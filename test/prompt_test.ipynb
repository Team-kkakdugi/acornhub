{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f5019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oli/olis_space/backend/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 라이브러리 임포트 완료 ---\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-genai konlpy keybert \"transformers>=4.31.0\" \"tokenizers>=0.13.3\" \"sentencepiece>=0.1.91\"\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import google.genai as genai\n",
    "from konlpy.tag import Okt\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(\"--- 라이브러리 임포트 완료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f13476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 초기화 중... (시간이 걸릴 수 있습니다) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oli/olis_space/backend/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모든 모델 초기화 완료 ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 모델 초기화 중... (시간이 걸릴 수 있습니다) ---\")\n",
    "try:\n",
    "    client = genai.Client(api_key=\"AIzaSyBhLmkl8pch1-aUmi3VsCsDRDYYjCgI2Dk\")\n",
    "    okt = Okt()\n",
    "    kw_model = KeyBERT('distiluse-base-multilingual-cased')\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"soddokayo/klue-roberta-large-klue-ner\", aggregation_strategy=\"simple\")\n",
    "    print(\"--- 모든 모델 초기화 완료 ---\")\n",
    "except Exception as e:\n",
    "    print(f\"모델 초기화 중 오류 발생: {e}\")\n",
    "    client = None\n",
    "    okt = None\n",
    "    kw_model = None\n",
    "    ner_pipeline = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f5aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 태그 후보 생성 중... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oli/olis_space/backend/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1369: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 생성된 태그 후보 (총 51개) ---\n",
      "['발표', '분야도 변화를', '편향성', '인간', '최근', '최근 구글', '작문', '기술이 빠르게', '빠르게 발전하면서', '맞이', '코딩', '인재', '책임감', '모델들은 작문', '인공', '번역 코딩', '인공지능', '하지만 모델의', '구글 오픈ai', '오픈AI', '기업', '발전', '초거대', '번역', '자연어', '영역에서 인간', '테크', '산업', '모델을 연이어', '모델들은', '환경', '모델', '거대', '모델의 편향성', '삼성전자', '걸쳐 혁신을', '변화', '연이어', '코딩 다양한', '분야', '지능', '발전하면서 자연어', '대한', '처리', '구글', '혁신을 주도하고', '이재용', '변화를 맞이하고', '기술', '이러한 모델들은', '오픈']\n"
     ]
    }
   ],
   "source": [
    "def get_tags_by_frequency(text, n_tags=20):\n",
    "    if not okt: return []\n",
    "    nouns = okt.nouns(re.sub(r'[^가-힣A-Za-z0-9\\s]', '', text))\n",
    "    return [n for n, c in Counter(n for n in nouns if len(n) > 1).most_common(n_tags)]\n",
    "\n",
    "def get_tags_by_keybert_ngrams(text, n_tags=20):\n",
    "    if not kw_model: return []\n",
    "    return [tag for tag, score in kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words=None, top_n=n_tags)]\n",
    "\n",
    "def get_tags_by_okt_phrases(text, n_tags=20):\n",
    "    if not kw_model or not okt: return []\n",
    "    phrases = okt.phrases(text)\n",
    "    if not phrases: return []\n",
    "    return [tag for tag, score in kw_model.extract_keywords(text, candidates=phrases, top_n=n_tags)]\n",
    "\n",
    "def get_tags_by_ner(text):\n",
    "    if not ner_pipeline: return []\n",
    "    return [entity['word'].replace(\" \", \"\") for entity in ner_pipeline(text)]\n",
    "\n",
    "card_text = \"\"\"\n",
    "인공지능(AI) 기술이 빠르게 발전하면서, 자연어 처리(NLP) 분야도 큰 변화를 맞이하고 있습니다.\n",
    "최근 구글, 오픈AI 등 빅테크 기업들은 초거대 AI 모델을 연이어 발표했습니다.\n",
    "이러한 모델들은 작문, 번역, 코딩 등 다양한 영역에서 인간 수준의 능력을 보여주며\n",
    "산업 전반에 걸쳐 혁신을 주도하고 있습니다. 하지만 모델의 편향성 문제와\n",
    "환경 비용에 대한 우려도 함께 제기되고 있어, 책임감 있는 AI 개발이 중요한 화두로 떠올랐습니다.\n",
    "이재용 삼성전자 회장은 AI 인재 확보의 중요성을 강조했습니다.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- 태그 후보 생성 중... ---\")\n",
    "if client: # 모델 로딩이 성공했을 때만 실행\n",
    "    freq_tags = get_tags_by_frequency(card_text)\n",
    "    ngram_tags = get_tags_by_keybert_ngrams(card_text)\n",
    "    phrase_tags = get_tags_by_okt_phrases(card_text)\n",
    "    ner_tags = get_tags_by_ner(card_text)\n",
    "    candidate_tags = list(set(freq_tags + ngram_tags + phrase_tags + ner_tags))\n",
    "\n",
    "    print(f\"\\n--- 생성된 태그 후보 (총 {len(candidate_tags)}개) ---\")\n",
    "    # 이 아래 리스트를 복사해서 다음 셀의 `candidate_tags` 변수에 붙여넣으세요.\n",
    "    print(candidate_tags)\n",
    "else:\n",
    "    print(\"모델이 제대로 로드되지 않아 후보를 생성할 수 없습니다.\")\n",
    "    candidate_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a514fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_tags = ['AI 모델', 'AI 인재', '최근 구글', '환경 비용', '빅테크 기업들', '인공지능', '삼성전자', '오픈AI', '자연어', '처리', '분야', '변화', '최근', '구글', '빅테크', '기업', '초거대', '모델', '발표', '작문', '번역', '코딩', '다양', '영역', '인간', '수준', '능력', '산업', '전반', '혁신', '주도', '문제', '우려', '제기', '책임감', '개발', '중요', '화두', '이재용', '회장', '인재', '확보', '강조', '기술', '발전', '자연어 처리', '인공지능 AI', 'AI 기술', '편향성 문제']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ee1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tags = 5\n",
    "prompt_template = f\"\"\"\n",
    "당신은 주어진 태그 후보 목록을 보고, 문서의 핵심 내용을 가장 잘 요약하는 최종 태그를 선택하고 다듬는 태그 전문가입니다.\n",
    "\n",
    "--- 태그 후보 목록 ---\n",
    "{', '.join(candidate_tags)}\n",
    "--------------------\n",
    "\n",
    "주어진 후보 목록 내에서, 가장 중요하고 대표성이 강한 키워드를 {max_tags}개만 선택해주세요.\n",
    "- 서로 의미가 겹치는 태그는 하나로 합쳐주세요 (예: '인공지능', 'AI' -> 'AI').\n",
    "- 너무 일반적이거나 중요도가 낮은 태그는 제외해주세요.\n",
    "- 최종 결과는 반드시 쉼표(,)로만 구분된 목록 형태로만 반환해주세요.\n",
    "\n",
    "예시 결과: AI, 자연어 처리, 빅테크, 편향성 문제, 삼성전자\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d866ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gemini-Pro에게 프롬프트 전송 (5개 요청) ---\n",
      "--- 사용된 프롬프트 ---\n",
      "\n",
      "당신은 주어진 태그 후보 목록을 보고, 문서의 핵심 내용을 가장 잘 요약하는 최종 태그를 선택하고 다듬는 태그 전문가입니다.\n",
      "\n",
      "--- 태그 후보 목록 ---\n",
      "AI 모델, AI 인재, 최근 구글, 환경 비용, 빅테크 기업들, 인공지능, 삼성전자, 오픈AI, 자연어, 처리, 분야, 변화, 최근, 구글, 빅테크, 기업, 초거대, 모델, 발표, 작문, 번역, 코딩, 다양, 영역, 인간, 수준, 능력, 산업, 전반, 혁신, 주도, 문제, 우려, 제기, 책임감, 개발, 중요, 화두, 이재용, 회장, 인재, 확보, 강조, 기술, 발전, 자연어 처리, 인공지능 AI, AI 기술, 편향성 문제\n",
      "--------------------\n",
      "\n",
      "주어진 후보 목록 내에서, 가장 중요하고 대표성이 강한 키워드를 5개만 선택해주세요.\n",
      "- 서로 의미가 겹치는 태그는 하나로 합쳐주세요 (예: '인공지능', 'AI' -> 'AI').\n",
      "- 너무 일반적이거나 중요도가 낮은 태그는 제외해주세요.\n",
      "- 최종 결과는 반드시 쉼표(,)로만 구분된 목록 형태로만 반환해주세요.\n",
      "\n",
      "예시 결과: AI, 자연어 처리, 빅테크, 편향성 문제, 삼성전자\n",
      "\n",
      "---------------------\n",
      "====================\n",
      " 최종 생성 태그\n",
      "====================\n",
      "['AI', '자연어 처리', '빅테크', '편향성 문제', '삼성전자']\n"
     ]
    }
   ],
   "source": [
    "final_tags = []\n",
    "if client and candidate_tags:\n",
    "    print(f\"\\n--- Gemini-Pro에게 프롬프트 전송 ({max_tags}개 요청) ---\\\n",
    "\")\n",
    "    print(\"--- 사용된 프롬프트 ---\")\n",
    "    print(prompt_template)\n",
    "    print(\"---------------------\\\n",
    "\")\n",
    "    try:\n",
    "        response = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt_template)\n",
    "        final_tags = [tag.strip() for tag in response.text.split(',')]\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 오류 발생: {e}\")\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\" 최종 생성 태그\")\n",
    "print(\"=\"*20)\n",
    "print(final_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f595969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
